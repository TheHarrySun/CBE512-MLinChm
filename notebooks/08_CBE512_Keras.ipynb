{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Notebook 08: Working with the Keras API**\n",
        "### CBE 512. Machine Learning in Chemical Science and Engineering.\n",
        "\n",
        "&#169; Princeton University"
      ],
      "metadata": {
        "id": "InhXhk7FX5hB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fP1k6KhzfrEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simple Demonstrations in Keras**\n",
        "\n",
        "In this notebook, we will examine how to build neural network regression models using [Keras](https://keras.io/about/). Keras itself makes prolific use of tools/objects/algorithms made available through [TensorFlow](https://www.tensorflow.org/guide/basics). These are available through `import` following setup of an appropriate python environment.\n",
        "\n",
        "Run the following cell to get access to all the things needed for this notebook."
      ],
      "metadata": {
        "id": "w0luGPdcJgwy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8Llsed0Ir0g"
      },
      "outputs": [],
      "source": [
        "# modules needed for this notebook\n",
        "import numpy  as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import pydot\n",
        "import graphviz\n",
        "import sklearn.metrics as sklm\n",
        "from tensorflow       import keras\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression,Ridge,Lasso"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *How to build Sequential models*\n",
        "\n",
        "The `Seqeuntial` model class from Keras provides a straightforward approach to building neural networks. The simplicity of implementation also necessitates some restrictions on the architecture complexity. Essentially, if you want the \"standard picture\" of a neural network, you can achieve that with a `Sequential` model. This will yield a densely connected, feed-forward neural network with a single input layer and a single output layer.  \n",
        "\n",
        "Let's take a look at how to do that below."
      ],
      "metadata": {
        "id": "1YqmtBSXJpAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Model Container\n",
        "model = keras.Sequential(name=\"myFirstModel\")\n",
        "\n",
        "# Define Layers\n",
        "inputLayer= keras.Input(shape=(4,))\n",
        "layer1= layers.Dense(10,activation='relu',name=\"myFirstLayer\")\n",
        "layer2= layers.Dense(8,activation='tanh',name=\"oldNewsLayer\")\n",
        "output= layers.Dense(1,activation=None,name=\"outputLayer\")\n",
        "\n",
        "# Add layers to model\n",
        "model.add(inputLayer)\n",
        "model.add(layer1)\n",
        "model.add(layer2)\n",
        "model.add(output)\n",
        "\n",
        "# Admire Model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "HxpecCgFJAzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *How to build models with Functional API*\n",
        "\n",
        "The `Functional` API allows users to create more flexible models/complex architectures that the `Sequential` API. For the majority of tasks, there may be no need to utilize a `Functional` API, but some more interesting ideas and model strategies can only be achieved using this approach. One reason that you may utilize the `Functional` API is if you have inputs that have disparate structures but still characterize your system. For example, you may have a microscopy image along with metadata on the sample; these are two very different data structures. The former is amenable to image-processing techniques (like a CNN) while the latter can be simply represented as a vector input. With the `Functional` API you can combine both inputs and let separate parts of your architecture process them independently before pooling the information.\n",
        "\n",
        "To start, let's recreate the network we made with `Sequential`."
      ],
      "metadata": {
        "id": "aBS11qOMJ1UP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Layers\n",
        "inputLayer = keras.Input(shape=(4,))\n",
        "layer1= layers.Dense(10,activation='relu',name=\"myFirstLayer\")\n",
        "layer2= layers.Dense(8,activation='tanh',name=\"oldNewsLayer\")\n",
        "output= layers.Dense(1,activation=None,name=\"output\")\n",
        "\n",
        "# Connect layers using \"layer calls\"\n",
        "# we want to achieve\n",
        "# inputLayer --> layer1 --> layer2 --> outputs\n",
        "x = layer1(inputLayer)\n",
        "x = layer2(x)\n",
        "outputs = output(x)\n",
        "\n",
        "# Build model from inputs/outputs\n",
        "model = keras.Model(inputs=inputLayer,outputs=outputs,\\\n",
        "        name=\"mySecondModel\")\n",
        "\n",
        "# Admire Model\n",
        "model.summary()\n",
        "keras.utils.plot_model(model,\"model.png\",dpi=100,show_shapes=True,show_layer_activations=True)"
      ],
      "metadata": {
        "id": "qYTWuxt1Jtam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's spice it up a little bit and create a split architecture. As a motivating premise, we can consider [this work](https://www.biorxiv.org/content/10.1101/2023.06.06.543884v1.abstract) studying properties of intrinsic disordered proteins. In this paper, authors use a 30-dimensional input vector, 20 of which correspond to the composition of amino acids within the polypeptide and 10 of which relate to aspects of the sequence and its patterning. Suppose we want to treat these types of data separately initially for a learning task. We could do that using an architecture like the following:"
      ],
      "metadata": {
        "id": "pfwCW8jrJ_J9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Layers\n",
        "inputLayer_comp = keras.Input(shape=(20,),name=\"composition\")\n",
        "inputLayer_seq  = keras.Input(shape=(10,),name=\"sequence stuff\")\n",
        "layer1_comp= layers.Dense(10,activation='relu',name=\"c1\")\n",
        "layer1_seq= layers.Dense(10,activation='relu',name=\"s1\")\n",
        "layer2_comp= layers.Dense(1,activation=None,name=\"c2\")\n",
        "layer2_seq= layers.Dense(5,activation='relu',name=\"s2\")\n",
        "layer3_seq= layers.Dense(1,activation=None,name=\"s3\")\n",
        "output= layers.Dense(1,activation=None,name=\"output\")\n",
        "\n",
        "# Connect layers using \"layer calls\"\n",
        "# we want to achieve\n",
        "# inputLayer --> layer1 --> layer2 --> outputs\n",
        "xs = layer3_seq(layer2_seq(layer1_seq(inputLayer_seq)))\n",
        "xc = layer2_comp(layer1_comp(inputLayer_comp))\n",
        "added = layers.concatenate([xs,xc])\n",
        "outputs = output(added)\n",
        "\n",
        "# Build model from inputs/outputs\n",
        "model = keras.Model(inputs=[inputLayer_comp,inputLayer_seq],outputs=outputs,\\\n",
        "        name=\"mySplitModel\")\n",
        "\n",
        "# Admire Model\n",
        "model.summary()\n",
        "keras.utils.plot_model(model,\"model.png\",show_shapes=True)"
      ],
      "metadata": {
        "id": "IZhvUuPGFnWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training a model in Keras**\n",
        "\n",
        "Now that we know how to build a model in Keras, we can see how easy it is to train/test one as well. For this, we are going to utilize some real data that you should have increasing familiarity with. This is the \"Solubility\" dataset that we have been exploring in class/on homeworks.\n",
        "\n",
        "The following cell will just retrieve the data and format it into relevant objects."
      ],
      "metadata": {
        "id": "ao5_BSfqIYYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in and inspect some of the data to gain some familiarity for what is in\n",
        "# the file. The rest of the code extracts some possible features and stores them\n",
        "# in an array X; the labels, which correspond to solubility values, are in y\n",
        "url_for_data    = \"https://raw.githubusercontent.com/webbtheosim/CBE512-MLinChmSciEng/main/data/solubility-regression-cbe512.csv\"\n",
        "data = pd.read_csv(\n",
        "    url_for_data\n",
        ")\n",
        "i0          = list(data.columns).index(\"MolWt\")\n",
        "allFeatures = data.columns[i0:-1]\n",
        "outLabel    = 'Solubility'\n",
        "X = np.array(data[allFeatures])\n",
        "nFeatures = X.shape[1]\n",
        "y = np.array(data[outLabel]).reshape([-1,1])\n",
        "print(X.shape,y.shape)\n",
        "print(X[0])\n",
        "print(y[0])\n",
        "data.head()"
      ],
      "metadata": {
        "id": "H-c4D7BWJ5c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing we want to do is do some preprocessing of the data. For this, we can use some of the tools from scikit-learn to get different transformations. Before we do this, I want to get a quick view of the data. This may not always be possible, but with 17 features, we can do it. The next couple of cells are not essential for anything with Keras but are for demonstration purposes."
      ],
      "metadata": {
        "id": "7YeRB9whMEUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_start_at = list(data.columns).index(\"MolWt\")\n",
        "feature_names = data.columns[features_start_at:]\n",
        "\n",
        "# code for pair correlations\n",
        "subset = [n for n in feature_names if np.random.random()<0.34]\n",
        "if outLabel not in subset:\n",
        "  subset.append(outLabel)\n",
        "sns.pairplot(data[subset],hue=outLabel)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZFCmJqX4Lk3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for looking at pair correlations with Solubility\n",
        "num_cols = 3\n",
        "num_rows = int( np.ceil(len(feature_names)/ num_cols))\n",
        "fig, axs = plt.subplots(nrows=num_rows,ncols=num_cols,sharey=True,figsize=(12,12))\n",
        "axs = axs.flatten()\n",
        "for i,n in enumerate(feature_names):\n",
        "  ax = axs[i]\n",
        "  ax.scatter(data[n], data.Solubility, s=6, alpha=0.4)\n",
        "  if i % num_cols == 0:\n",
        "    ax.set_ylabel(\"Solubility\")\n",
        "  ax.set_xlabel(n)\n",
        "  plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4TlrBF_FUZIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a train-test split\n",
        "\n",
        "OK. We have seen the data. There are some correlated features. We are not going to worry about this significantly right now, but we should be mindful of that were we wanting to create the best model that we could. Following a minimal set of \"best practices,\" let's create a test-train split and get on with the model training."
      ],
      "metadata": {
        "id": "9t-JpkatKu3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the split\n",
        "(X_train, X_test, y_train, y_test) \\\n",
        "   = train_test_split(X,y,test_size = 0.2,shuffle=True)\n",
        "\n",
        "# Perform data transformations\n",
        "inScaler = StandardScaler() # scaler for features\n",
        "outScaler= StandardScaler() # scaler for labels\n",
        "inScaler.fit(X_train)\n",
        "outScaler.fit(y_train)\n",
        "Xsc_train = inScaler.transform(X_train)  # these are the scaled features for training\n",
        "ysc_train = outScaler.transform(y_train) # these are the scaled labels for training\n",
        "Xsc_test = inScaler.transform(X_test)  # these are the scaled features for training\n",
        "ysc_test = outScaler.transform(y_test) # these are the scaled labels for training\n",
        "\n",
        "# check the data distribution\n",
        "bins    = np.arange(-3,3.1,0.2)\n",
        "fig, ax = plt.subplots(figsize=(5,5),sharey=True)\n",
        "ax.hist(ysc_train,bins=bins,histtype='bar',align='mid',\\\n",
        "        label='train',alpha = 0.4,edgecolor='k')\n",
        "ax.hist(ysc_test,bins=bins,histtype='bar',align='mid',\\\n",
        "        label='test',alpha = 0.4,edgecolor='k')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BFbiN2GuNJxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Build and train a model**\n",
        "\n",
        "All righty then. Let's whip up a model and train that sucker. Since we are not dealing with anything too fancy, we will roll with the `Sequential` API. Feel free to use `Functional` if you prefer and want that practice."
      ],
      "metadata": {
        "id": "wGJ-9oLpRH9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nFeatures = X_train.shape[1] # dimensionality of our input vecto\n",
        "model  = keras.Sequential () # this initializes our simple model, but it doesn't have anhything in it!\n",
        "hidden1= layers.Dense(20,activation=\"relu\") # here we create 20-neuron layer with relu activation\n",
        "hidden2= layers.Dense(5,activation=\"relu\")  # this is a 5-neuron layer, again with relu\n",
        "out    = layers.Dense(1)    # we will only have one output, activation=None means linear/identity\n",
        "model.add(hidden1)\n",
        "model.add(hidden2)\n",
        "model.add(out)\n",
        "model.build((None,nFeatures)) # this last line specifies the input shape; there are lots of ways to do this\n",
        "model.summary()\n",
        "keras.utils.plot_model(model,\"model.png\",dpi=100,show_shapes=True)"
      ],
      "metadata": {
        "id": "oIbpWVGIRC12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up model optimization specifications through compile\n",
        "the_optimizer = tf.keras.optimizers.SGD(\\\n",
        "      learning_rate= 0.005, momentum=0.0,nesterov=False,name='SGD')\n",
        "the_loss      = tf.keras.losses.MeanSquaredError(reduction=\"sum_over_batch_size\",name=\"MSE\")\n",
        "model.compile(optimizer=the_optimizer,loss=the_loss)"
      ],
      "metadata": {
        "id": "cv8-H1fSRTSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now actually do the training\n",
        "hist = model.fit(x=Xsc_train,y=ysc_train,\\\n",
        "          batch_size=32,\n",
        "          epochs=100,\n",
        "          validation_split = 0.1,\n",
        "          shuffle=True)"
      ],
      "metadata": {
        "id": "xBEeNb0mVKhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspecting model training\n",
        "\n",
        "By following the output from above, we can get some sense as to how effective our model is learning. However, it may be informative to more directly inspect this in the form of a *training curve*."
      ],
      "metadata": {
        "id": "Gm8Z0naGmomj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(hist.history.keys())\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "plt.plot(loss,'-k',linewidth=2)\n",
        "plt.plot(val_loss,':r',linewidth=2)\n",
        "ax = plt.gca()\n",
        "ax.set_ylim([0,1])\n",
        "ax.set_xlabel(\"Epochs\")\n",
        "ax.set_ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KQayRRh7V80f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making predictions\n",
        "Based on our training curve, it looks like we have a pretty fair model. Let's see how it performs on our held-out test set by using the `predict` method."
      ],
      "metadata": {
        "id": "cqDdkQF5p3Rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ysc_pred = model.predict(Xsc_test)\n",
        "ypred   = outScaler.inverse_transform(ysc_pred)\n",
        "plt.plot(y_test,ypred,\".\")\n",
        "linearFit = LinearRegression().fit(y_test,ypred)\n",
        "r2 = sklm.r2_score(y_test,ypred)\n",
        "mae= sklm.mean_absolute_error(y_test,ypred)\n",
        "mse=sklm.mean_squared_error(y_test,ypred)\n",
        "print(\"r2 = {:>5.2f}, mae = {:>5.2f}, mse = {:>5.2f}\".format(r2,mae,mse))\n",
        "xline = np.array([[-14],[4]])\n",
        "yline = linearFit.predict(xline)\n",
        "plt.plot(xline,yline,'-r')\n",
        "plt.plot(xline,xline,':k')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "e3axfDUGnCEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oZqNTjZktt-m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}